# app.py
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
from matplotlib.ticker import MaxNLocator
import seaborn as sns
import openai
import sys
import os
import io
from datetime import datetime

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.analysis.categorize import run_keyword_analysis, generate_wordcloud_from_freq
from modules.analysis.summary_module import generate_summary_with_gpt
from modules.analysis.sentiment_module import (
    analyze_sentiment_with_finbert,
    refine_neutral_keywords_with_gpt,
    merge_sentiment_results,
    summarize_sentiment_by_category
)
from modules.analysis_pipeline import AnalysisPipeline
from langchain_openai import ChatOpenAI
from modules.question_detector import detect_question_columns
from modules.make_longformat import make_longformat

# í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="HR ì‘ë‹µ ë¶„ì„", layout="wide")

# GPT ëª¨ë¸ ì •ì˜
llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
    openai_api_key=st.secrets["openai_section"]["api_key"]
)

# í˜ì´ì§€ ì„ íƒ
menu = st.sidebar.selectbox("í˜ì´ì§€ ì„ íƒ", ["ğŸ  í™ˆ", "ğŸ“Š ë¶„ì„", "âš™ï¸ ì„¤ì •"])

# í™ˆ í˜ì´ì§€
if menu == "ğŸ  í™ˆ":
    st.title("ğŸ’¼ HR ì‘ë‹µ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # 1. íŒŒì¼ ì—…ë¡œë“œ
    uploaded = st.file_uploader("ğŸ“‚ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"])
    
    # 2. ë¶„ì„ ì‹œì‘
    if uploaded:
        df = pd.read_excel(uploaded)
        st.success("ì—…ë¡œë“œ ì™„ë£Œ!")
        st.dataframe(df.head())
        
        st.write("---")

        analysis_mode = st.radio(
            "ë¶„ì„ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.",
            ("ì „ì²´ ëŒ€ìƒì ë¶„ì„", "íŠ¹ì • ëŒ€ìƒì ë¶„ì„"),
            horizontal=True
        )
        
        id_col = st.selectbox("ID ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”.", df.columns.tolist())
        selected_subject = None
        if analysis_mode == "íŠ¹ì • ëŒ€ìƒì ë¶„ì„":
            if id_col:
                subject_list = df[id_col].dropna().unique().tolist()
                selected_subject = st.selectbox("ë¶„ì„í•  ëŒ€ìƒìë¥¼ ì„ íƒí•˜ì„¸ìš”.", subject_list)

        with st.form("analysis_form"):
            st.subheader("ğŸ’¡ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´ ì…ë ¥")
            user_prompt = st.text_area(
                "ì´ ë°ì´í„°ëŠ” ë¬´ì—‡ì— ëŒ€í•œ ë°ì´í„°ì¸ê°€ìš”? (ì˜ˆ: 'ì§ì› ë§Œì¡±ë„ ì„¤ë¬¸ì¡°ì‚¬', 'íŒ€ ë™ë£Œ í‰ê°€ ë°ì´í„°')",
                key="user_prompt"
            )
            use_llm = st.checkbox("GPTê°€ ìë™ìœ¼ë¡œ ì§ˆë¬¸ ì»¬ëŸ¼ì„ ì°¾ì•„ë‚´ë„ë¡ í•˜ê¸°", value=True)
            submitted = st.form_submit_button("ë¶„ì„ ì‹œì‘")

        if submitted:
            if not user_prompt.strip():
                st.error("ë°ì´í„°ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                # ğŸš¨ ìˆ˜ì •ëœ ë¶€ë¶„: ë¶„ì„ê³¼ ì €ì¥ì„ í•˜ë‚˜ì˜ ë£¨í”„ì—ì„œ ì²˜ë¦¬
                
                # GPTê°€ ì§ˆë¬¸ ì»¬ëŸ¼ì„ íƒì§€
                with st.spinner("âœ¨ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘..."):
                    question_cols = []
                    if use_llm:
                        st.info("AIê°€ ì§ˆë¬¸ ì»¬ëŸ¼ì„ íƒì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
                        question_cols = detect_question_columns(df.columns.tolist(), section_name="openai_section")
                        if not question_cols:
                            st.warning("GPTê°€ ì§ˆë¬¸ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ì»¬ëŸ¼ì„ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.")
                            question_cols = [col for col in df.columns if col != id_col]
                    else:
                        question_cols = [col for col in df.columns if col != id_col]
                    st.success(f"âœ”ï¸ ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼: {question_cols}")
                
                # ë¶„ì„ ëŒ€ìƒì ë¦¬ìŠ¤íŠ¸ ì •ì˜
                if analysis_mode == "íŠ¹ì • ëŒ€ìƒì ë¶„ì„" and selected_subject:
                    subjects_to_analyze = [selected_subject]
                else:
                    subjects_to_analyze = df[id_col].dropna().unique().tolist()

                now = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name_prefix = uploaded.name.split('.')[0]
                base_dir = f"./{file_name_prefix}_{now}"
                analysis_dir = base_dir
                
                st.markdown("---")
                st.subheader("ğŸ“¦ ë¶„ì„ ë° ê²°ê³¼ ì €ì¥")
                progress_bar = st.progress(0, text=f"ë¶„ì„ ë° ì €ì¥ ì§„í–‰ ì¤‘ (0 / {len(subjects_to_analyze)})")

                with st.spinner("ë¶„ì„ ë° íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        for i, subject in enumerate(subjects_to_analyze):
                            st.info(f"âœ¨ '{subject}'ì— ëŒ€í•œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                            
                            filtered_df = df[df[id_col] == subject].copy()
                            long_df, _ = make_longformat(filtered_df, id_column=id_col, use_llm=False)
                            long_df = long_df[long_df['ì§ˆë¬¸'].isin(question_cols)]
                            
                            st.subheader("ğŸ“ Long Format ë³€í™˜ ê²°ê³¼")
                            st.dataframe(long_df)

                            texts = long_df['ì‘ë‹µ'].tolist()

                            if not texts:
                                st.warning(f"'{subject}'ì— ëŒ€í•œ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ëŒ€ìƒìë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                                progress_bar.progress((i + 1) / len(subjects_to_analyze), text=f"ë¶„ì„ ë° ì €ì¥ ì§„í–‰ ì¤‘ ({i + 1} / {len(subjects_to_analyze)})")
                                continue

                            pipeline = AnalysisPipeline(llm, long_df)
                            if pipeline.run():
                                results = pipeline.get_results()

                                # ê° ëŒ€ìƒìë³„ í´ë” ìƒì„±
                                participant_dir = os.path.join(analysis_dir, subject)
                                os.makedirs(participant_dir, exist_ok=True)
                                st.info(f"ë¶„ì„ ê²°ê³¼ê°€ '{participant_dir}' í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")
                                
                                # ì‹œê°í™”ëŠ” ì €ì¥í•  ë•Œ ìƒì„±
                                fig_wc, ax_wc = plt.subplots()
                                wc = generate_wordcloud_from_freq(results['freq_df'])
                                if wc:
                                    ax_wc.imshow(wc, interpolation='bilinear')
                                    ax_wc.axis('off')
                                else:
                                    st.warning(f"'{subject}'ì— ëŒ€í•œ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨.")

                                fig_bar, ax_bar = plt.subplots()
                                freq_df = results['freq_df'].copy()
                                freq_df["count"] = freq_df["count"].astype(int)
                                freq_plot_df = freq_df.sort_values(by="count", ascending=False).head(20)
                                sns.barplot(data=freq_plot_df, y='keyword', x='count', hue='category', dodge=False, ax=ax_bar)
                                ax_bar.xaxis.set_major_locator(MaxNLocator(integer=True))
                                ax_bar.set_ylabel("í‚¤ì›Œë“œ")
                                ax_bar.set_xlabel("count")
                                
                                overall_sentiment = results['sentiment_summary'].groupby('sentiment')['percentage'].sum().reset_index()
                                fig_pie = px.pie(
                                    overall_sentiment,
                                    names='sentiment',
                                    values='percentage',
                                    title='ì „ì²´ ê°ì • ë¶„í¬ (ëª¨ë“  í‚¤ì›Œë“œ ê¸°ì¤€)',
                                    color='sentiment',
                                    color_discrete_map={'ê¸ì •': '#63b2ee', 'ë¶€ì •': '#ff9999', 'ì¤‘ë¦½': '#ffcc66'}
                                )
                                
                                # íŒŒì¼ ì €ì¥
                                results['freq_df'].to_csv(os.path.join(participant_dir, "keyword_freq.csv"), index=False)
                                results['updated_df'].to_csv(os.path.join(participant_dir, "sentiment.csv"), index=False)
                                if wc:
                                    fig_wc.savefig(os.path.join(participant_dir, "wordcloud.png"))
                                fig_pie.write_image(os.path.join(participant_dir, "piechart.png"))
                                fig_bar.savefig(os.path.join(participant_dir, "barchart.png"))
                                summary_df = pd.DataFrame([{'summary': results['summary_text']}])
                                summary_df.to_csv(os.path.join(participant_dir, "summary.csv"), index=False)
                                
                                st.success(f"âœ”ï¸ '{subject}' ë¶„ì„ ë° ì €ì¥ ì™„ë£Œ!")
                            progress_bar.progress((i + 1) / len(subjects_to_analyze), text=f"ë¶„ì„ ë° ì €ì¥ ì§„í–‰ ì¤‘ ({i + 1} / {len(subjects_to_analyze)})")
                        
                        st.success("âœ”ï¸ ëª¨ë“  ëŒ€ìƒì ë¶„ì„ ë° ì €ì¥ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.warning("PDF ë³´ê³ ì„œ ìƒì„± ê¸°ëŠ¥ì€ í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        
                        # ì €ì¥ ê²½ë¡œë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                        if 'last_analysis_path' not in st.session_state:
                            st.session_state.last_analysis_path = {}
                        st.session_state.last_analysis_path[os.path.basename(base_dir)] = analysis_dir
                        
                        # ë¶„ì„ í˜ì´ì§€ë¡œ ì´ë™
                        st.session_state['menu'] = 'ğŸ“Š ë¶„ì„'
                        st.rerun()

                    except Exception as e:
                        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ğŸ“Š ë¶„ì„ í˜ì´ì§€
elif menu == "ğŸ“Š ë¶„ì„":
    st.title("ğŸ“Š ë¶„ì„ ê²°ê³¼ í™•ì¸")
    st.write("ë¶„ì„ ê²°ê³¼ë¥¼ í´ë”ë³„ë¡œ íƒìƒ‰í•˜ê³  í™•ì¸í•˜ì„¸ìš”.")
    
    # ğŸš¨ ì¶”ê°€ëœ ë¶€ë¶„: ê²½ë¡œ ì…ë ¥ í•„ë“œ
    path_input = st.text_input(
        "í™•ì¸í•  ë¶„ì„ ê²°ê³¼ì˜ ìƒìœ„ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
        value="",
        placeholder="ì˜ˆ: ./ë°ì´í„°ê°€ë§ì€í¸_ë¦¬ë”ì‹­,ì¡°ì§ë¬¸í™” ë‹¤ë©´ì§„ë‹¨ Data_2023_20250821_233332"
    )
    
    # ğŸš¨ ìˆ˜ì •ëœ ë¶€ë¶„: ê²½ë¡œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¡œì§
    current_path = None
    if path_input:
        if os.path.isdir(path_input):
            current_path = path_input
        else:
            st.error("âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ë¡œì…ë‹ˆë‹¤. í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    elif 'last_analysis_path' in st.session_state and st.session_state.last_analysis_path:
        selected_key = st.selectbox(
            "ìµœê·¼ ë¶„ì„ ê²°ê³¼ í´ë”ë¥¼ ì„ íƒí•˜ê±°ë‚˜, ìœ„ ê²½ë¡œë¥¼ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.",
            list(st.session_state.last_analysis_path.keys())
        )
        if selected_key:
            current_path = st.session_state.last_analysis_path[selected_key]
    else:
        st.info("ì•„ì§ ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'í™ˆ' í˜ì´ì§€ì—ì„œ ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")

    if current_path:
        st.write(f"ğŸ“‚ í˜„ì¬ ê²½ë¡œ: `{current_path}`")
        
        # í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        files = [f for f in os.listdir(current_path) if os.path.isdir(os.path.join(current_path, f))]
        sorted_files = sorted(files, key=lambda x: int(x.split('ëŒ€ìƒì')[1]))

        selected_file_name = st.selectbox(
            "ë¶„ì„ ëŒ€ìƒì í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
            sorted_files
        )
        
        if selected_file_name:
            file_path = os.path.join(current_path, selected_file_name)
            
            inner_files = [f for f in os.listdir(file_path) if os.path.isfile(os.path.join(file_path, f))]

            for file in inner_files:
                inner_file_path = os.path.join(file_path, file)
                file_extension = os.path.splitext(file)[1].lower()
                
                if file_extension in ['.csv', '.txt']:
                    st.subheader(f"ğŸ“„ {file}")
                    df_or_text = pd.read_csv(inner_file_path) if file_extension == '.csv' else open(inner_file_path, 'r', encoding='utf-8').read()
                    st.code(df_or_text.to_csv(index=False) if file_extension == '.csv' else df_or_text)
                elif file_extension in ['.png', '.jpg', '.jpeg']:
                    st.subheader(f"ğŸ–¼ï¸ {file}")
                    st.image(inner_file_path)

# âš™ï¸ ì„¤ì • í˜ì´ì§€
elif menu == "âš™ï¸ ì„¤ì •":
    st.title("âš™ï¸ ì„¤ì •")
    st.write("API í‚¤ ë“± ì„¤ì • ê°€ëŠ¥")